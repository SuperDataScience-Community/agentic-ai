{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f663a39e",
   "metadata": {},
   "source": [
    "# Building Advanced Multi-Agent Systems with Tools, Handoffs, and Structured Outputs\n",
    "\n",
    "Hey everyone! Welcome back to another exciting lesson on Agentic AI! üéâ\n",
    "\n",
    "In this lab, we'll explore:\n",
    "\n",
    "- **Agent Tools**: Using hosted tools (WebSearchTool), building custom function tools and using agents as tools\n",
    "- **Agent Handoffs**: Implementing intelligent routing between specialist agents\n",
    "- **Structured Outputs**: Using Pydantic models for deterministic, type-safe responses\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca612b9",
   "metadata": {},
   "source": [
    "# Agent Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae3da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from agents import Agent, Runner, WebSearchTool, function_tool\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bdd36c",
   "metadata": {},
   "source": [
    "### Hosted Tools\n",
    "\n",
    "These are tools provided to us by OpenAI. They are plug and play which means they don't require us to write out functions or do much configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d0aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_research_agent = Agent(\n",
    "    name=\"FinancialResearchBot\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=\"You are a financial research assistant. Provide detailed and accurate financial information about companies by looking up their financial reports.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f92c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_research_agent = Agent(\n",
    "    name=\"FinancialResearchBot\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=\"You are a financial research assistant. Provide detailed and accurate financial information about companies by looking up their financial reports.\",\n",
    "    tools=[WebSearchTool()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ea1d472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To provide a well-informed recommendation on whether to buy, sell, or hold Apple stock, I would need to review the latest financial data and market conditions for Apple Inc. (AAPL). Here‚Äôs the type of information I would analyze:\n",
      "\n",
      "1. Recent Financial Performance:\n",
      "   - Latest quarterly earnings and revenue\n",
      "   - Profit margins and net income trends\n",
      "   - Cash flow and balance sheet strength (cash reserves, debt levels)\n",
      "\n",
      "2. Market Conditions:\n",
      "   - Current stock price and valuation metrics (P/E ratio, PEG ratio)\n",
      "   - Comparison to sector and broader market indices\n",
      "   - Recent stock performance and volatility\n",
      "\n",
      "3. Growth Prospects:\n",
      "   - Product launches and innovation pipeline\n",
      "   - Service segment growth (App Store, iCloud, etc.)\n",
      "   - Market expansion opportunities\n",
      "\n",
      "4. Analyst Ratings:\n",
      "   - Consensus recommendations from Wall Street analysts\n",
      "   - Target price vs current price\n",
      "\n",
      "5. Risks:\n",
      "   - Supply chain issues, regulation, or macroeconomic factors\n",
      "   - Competitive landscape\n",
      "\n",
      "Could you please confirm if you want me to pull and analyze the latest quarterly report and market data for Apple to proceed with the recommendation? If yes, I can provide a comprehensive analysis based on the most recent available data.\n"
     ]
    }
   ],
   "source": [
    "results = await Runner.run(financial_research_agent, \"I want you to make a recommendation on whether to buy, sell or hold Apple stock based on the current market conditions.\")\n",
    "print(results.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e31b7a",
   "metadata": {},
   "source": [
    "### Custom Tools\n",
    "\n",
    "These are tools we build ourselves and provide our agents access to use them. Remember that all they are, are python functions that do a specific task (eg. call an API, get data from a database, perform a calculation/logic, etc.)\n",
    "\n",
    "[Tavily](https://app.tavily.com/home) is a great API service which we will use for this example of trying to search the web for relevant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e125e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "@function_tool\n",
    "def tavily_search_tool(query: str, include_answer: str = \"basic\") -> str:\n",
    "    \"\"\"\n",
    "    Search for information using the Tavily API.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query.\n",
    "        include_answer (str): The level of detail to include in the answer. Options are \"basic\", \"detailed\", or \"full\".\n",
    "\n",
    "    Returns:\n",
    "        dict: The search results from Tavily.\n",
    "    \"\"\"\n",
    "    client = TavilyClient(TAVILY_API_KEY)\n",
    "    response = client.search(\n",
    "        query=query,\n",
    "        include_answer=include_answer\n",
    "    )\n",
    "    formatted_response = format_tavily_results(response)\n",
    "    return formatted_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3556bb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tavily_search_tool',\n",
       " 'description': 'Search for information using the Tavily API.',\n",
       " 'params_json_schema': {'properties': {'query': {'description': 'The search query.',\n",
       "    'title': 'Query',\n",
       "    'type': 'string'},\n",
       "   'include_answer': {'default': 'basic',\n",
       "    'description': 'The level of detail to include in the answer. Options are \"basic\", \"detailed\", or \"full\".',\n",
       "    'title': 'Include Answer',\n",
       "    'type': 'string'}},\n",
       "  'required': ['query', 'include_answer'],\n",
       "  'title': 'tavily_search_tool_args',\n",
       "  'type': 'object',\n",
       "  'additionalProperties': False},\n",
       " 'on_invoke_tool': <function agents.tool.function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool(ctx: 'ToolContext[Any]', input: 'str') -> 'Any'>,\n",
       " 'strict_json_schema': True,\n",
       " 'is_enabled': True,\n",
       " 'tool_input_guardrails': None,\n",
       " 'tool_output_guardrails': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_search_tool.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "917e66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_tavily_results(tavily_response: dict) -> str:\n",
    "    \"\"\"\n",
    "    Format Tavily search results into a clean, LLM-friendly format.\n",
    "    \n",
    "    Args:\n",
    "        tavily_response: Raw Tavily API response\n",
    "        \n",
    "    Returns:\n",
    "        Formatted string with search results\n",
    "    \"\"\"\n",
    "    formatted = f\"# Search Results for: {tavily_response['query']}\\n\\n\"\n",
    "    \n",
    "    # Add the AI-generated answer if available\n",
    "    if tavily_response.get('answer'):\n",
    "        formatted += f\"## Summary\\n{tavily_response['answer']}\\n\\n\"\n",
    "    \n",
    "    # Add top search results\n",
    "    formatted += \"## Detailed Sources\\n\\n\"\n",
    "    for idx, result in enumerate(tavily_response['results'][:5], 1):  # Limit to top 5\n",
    "        formatted += f\"### {idx}. {result['title']}\\n\"\n",
    "        formatted += f\"**URL:** {result['url']}\\n\"\n",
    "        formatted += f\"**Relevance Score:** {result['score']:.2f}\\n\\n\"\n",
    "        formatted += f\"{result['content'][:500]}...\\n\\n\"  # Truncate long content\n",
    "        formatted += \"---\\n\\n\"\n",
    "    \n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f045b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionTool(name='tavily_search_tool', description='Search for information using the Tavily API.', params_json_schema={'properties': {'query': {'description': 'The search query.', 'title': 'Query', 'type': 'string'}, 'include_answer': {'default': 'basic', 'description': 'The level of detail to include in the answer. Options are \"basic\", \"detailed\", or \"full\".', 'title': 'Include Answer', 'type': 'string'}}, 'required': ['query', 'include_answer'], 'title': 'tavily_search_tool_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x0000024768B84AE0>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_search_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "911711d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacation_agent = Agent(\n",
    "    name=\"VacationPlannerBot\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=\"You are a vacation planning assistant. Help users plan their vacations by providing recommendations on destinations, activities, and accommodations.\",\n",
    "    tools=[tavily_search_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b14a15e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunResult:\n",
      "- Last agent: Agent(name=\"VacationPlannerBot\", ...)\n",
      "- Final output (str):\n",
      "    Visiting Japan in the spring is a wonderful choice, especially for enjoying the cherry blossoms and pleasant weather. Here are some great activities and places to consider for your trip:\n",
      "    \n",
      "    1. Tokyo:\n",
      "       - Visit Ueno Park or Shinjuku Gyoen for beautiful cherry blossom viewing.\n",
      "       - Explore the historic Asakusa district and Senso-ji Temple.\n",
      "       - Enjoy shopping and entertainment in Shibuya and Harajuku.\n",
      "    \n",
      "    2. Kyoto:\n",
      "       - See cherry blossoms at Maruyama Park and the Philosopher's Path.\n",
      "       - Visit iconic temples such as Kinkaku-ji (Golden Pavilion) and Fushimi Inari Shrine.\n",
      "       - Experience a traditional tea ceremony.\n",
      "    \n",
      "    3. Osaka:\n",
      "       - Explore Osaka Castle and its surrounding park.\n",
      "       - Visit the bustling Dotonbori area for street food and nightlife.\n",
      "       - Take a day trip to nearby Nara to see the famous deer park and Todai-ji Temple.\n",
      "    \n",
      "    4. Hiroshima:\n",
      "       - Visit the Peace Memorial Park and Museum.\n",
      "       - Take a ferry to Miyajima Island to see the famous floating torii gate.\n",
      "    \n",
      "    5. Hakone:\n",
      "       - Enjoy hot springs (onsen) with views of Mount Fuji.\n",
      "       - Take a scenic boat ride on Lake Ashi.\n",
      "    \n",
      "    6. Activities:\n",
      "       - Participate in hanami (cherry blossom viewing) picnics.\n",
      "       - Try seasonal spring foods like sakura mochi (cherry blossom rice cakes).\n",
      "       - Experience traditional festivals like the Takayama Spring Festival.\n",
      "    \n",
      "    Would you like recommendations for accommodations, transportation tips, or specific festivals during your visit?\n",
      "- 1 new item(s)\n",
      "- 1 raw response(s)\n",
      "- 0 input guardrail result(s)\n",
      "- 0 output guardrail result(s)\n",
      "(See `RunResult` for more details)\n"
     ]
    }
   ],
   "source": [
    "results = await Runner.run(vacation_agent, \"I want to plan a vacation to Japan in the spring. Can you suggest some activities and places to visit?\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2bcede4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Visiting Japan in the spring is a wonderful choice, especially for enjoying the cherry blossoms and pleasant weather. Here are some great activities and places to consider for your trip:\\n\\n1. Tokyo:\\n   - Visit Ueno Park or Shinjuku Gyoen for beautiful cherry blossom viewing.\\n   - Explore the historic Asakusa district and Senso-ji Temple.\\n   - Enjoy shopping and entertainment in Shibuya and Harajuku.\\n\\n2. Kyoto:\\n   - See cherry blossoms at Maruyama Park and the Philosopher's Path.\\n   - Visit iconic temples such as Kinkaku-ji (Golden Pavilion) and Fushimi Inari Shrine.\\n   - Experience a traditional tea ceremony.\\n\\n3. Osaka:\\n   - Explore Osaka Castle and its surrounding park.\\n   - Visit the bustling Dotonbori area for street food and nightlife.\\n   - Take a day trip to nearby Nara to see the famous deer park and Todai-ji Temple.\\n\\n4. Hiroshima:\\n   - Visit the Peace Memorial Park and Museum.\\n   - Take a ferry to Miyajima Island to see the famous floating torii gate.\\n\\n5. Hakone:\\n   - Enjoy hot springs (onsen) with views of Mount Fuji.\\n   - Take a scenic boat ride on Lake Ashi.\\n\\n6. Activities:\\n   - Participate in hanami (cherry blossom viewing) picnics.\\n   - Try seasonal spring foods like sakura mochi (cherry blossom rice cakes).\\n   - Experience traditional festivals like the Takayama Spring Festival.\\n\\nWould you like recommendations for accommodations, transportation tips, or specific festivals during your visit?\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51edb13e",
   "metadata": {},
   "source": [
    "### Agents as Tools\n",
    "\n",
    "We can provide our agents access to other agents as tools. This differs slightly from handoffs which we will have a look at later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63704fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_agent = Agent(\n",
    "    name=\"MathSolverBot\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=\"You are a math problem solver. Provide step-by-step solutions to mathematical problems.\",\n",
    ")\n",
    "\n",
    "history_agent = Agent(\n",
    "    name=\"HistoryExpertBot\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=\"You are a history expert. Provide detailed historical information and context about various events and figures.\",\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"TriageAgent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=\"You are a triage agent. Determine whether a user's query is best handled by the MathSolverBot or the HistoryExpertBot, and route the query accordingly.\",\n",
    "    tools=[\n",
    "        math_agent.as_tool(\n",
    "            tool_name=\"MathSolverTool\",\n",
    "            tool_description=\"Use this tool to solve mathematical problems.\"\n",
    "        ),\n",
    "        history_agent.as_tool(\n",
    "            tool_name=\"HistoryExpertTool\",\n",
    "            tool_description=\"Use this tool to provide detailed historical information and context.\"\n",
    "        )\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22f3a841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunResult:\n",
      "- Last agent: Agent(name=\"TriageAgent\", ...)\n",
      "- Final output (str):\n",
      "    The integral of \\( x^2 \\) is \\(\\frac{x^3}{3} + C\\), where \\(C\\) is the constant of integration.\n",
      "- 3 new item(s)\n",
      "- 2 raw response(s)\n",
      "- 0 input guardrail result(s)\n",
      "- 0 output guardrail result(s)\n",
      "(See `RunResult` for more details)\n"
     ]
    }
   ],
   "source": [
    "results = await Runner.run(triage_agent, \"What is the integral of x^2?\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdbc5a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the integral of x^2?',\n",
       " 'new_items': [ToolCallItem(agent=Agent(name='TriageAgent', handoff_description=None, tools=[FunctionTool(name='MathSolverTool', description='Use this tool to solve mathematical problems.', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'MathSolverTool_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x000002476C2D4720>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None), FunctionTool(name='HistoryExpertTool', description='Use this tool to provide detailed historical information and context.', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'HistoryExpertTool_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x000002476C2D4A40>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions=\"You are a triage agent. Determine whether a user's query is best handled by the MathSolverBot or the HistoryExpertBot, and route the query accordingly.\", prompt=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"input\":\"integral of x^2\"}', call_id='call_WpGoEEMr9a6gEkl0TVoL4a66', name='MathSolverTool', type='function_call', id='fc_0df535c959448d2600692fe7dcf1d8819ab9f83b3ceeef8cf8', status='completed'), type='tool_call_item'),\n",
       "  ToolCallOutputItem(agent=Agent(name='TriageAgent', handoff_description=None, tools=[FunctionTool(name='MathSolverTool', description='Use this tool to solve mathematical problems.', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'MathSolverTool_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x000002476C2D4720>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None), FunctionTool(name='HistoryExpertTool', description='Use this tool to provide detailed historical information and context.', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'HistoryExpertTool_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x000002476C2D4A40>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions=\"You are a triage agent. Determine whether a user's query is best handled by the MathSolverBot or the HistoryExpertBot, and route the query accordingly.\", prompt=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_WpGoEEMr9a6gEkl0TVoL4a66', 'output': 'To find the integral of \\\\( x^2 \\\\), we use the power rule for integration:\\n\\n\\\\[\\n\\\\int x^n \\\\, dx = \\\\frac{x^{n+1}}{n+1} + C, \\\\quad \\\\text{for } n \\\\neq -1\\n\\\\]\\n\\nHere, \\\\( n = 2 \\\\), so\\n\\n\\\\[\\n\\\\int x^2 \\\\, dx = \\\\frac{x^{2+1}}{2+1} + C = \\\\frac{x^3}{3} + C\\n\\\\]\\n\\nwhere \\\\( C \\\\) is the constant of integration.\\n\\n**Final answer:**\\n\\n\\\\[\\n\\\\boxed{\\\\int x^2 \\\\, dx = \\\\frac{x^3}{3} + C}\\n\\\\]', 'type': 'function_call_output'}, output='To find the integral of \\\\( x^2 \\\\), we use the power rule for integration:\\n\\n\\\\[\\n\\\\int x^n \\\\, dx = \\\\frac{x^{n+1}}{n+1} + C, \\\\quad \\\\text{for } n \\\\neq -1\\n\\\\]\\n\\nHere, \\\\( n = 2 \\\\), so\\n\\n\\\\[\\n\\\\int x^2 \\\\, dx = \\\\frac{x^{2+1}}{2+1} + C = \\\\frac{x^3}{3} + C\\n\\\\]\\n\\nwhere \\\\( C \\\\) is the constant of integration.\\n\\n**Final answer:**\\n\\n\\\\[\\n\\\\boxed{\\\\int x^2 \\\\, dx = \\\\frac{x^3}{3} + C}\\n\\\\]', type='tool_call_output_item'),\n",
       "  MessageOutputItem(agent=Agent(name='TriageAgent', handoff_description=None, tools=[FunctionTool(name='MathSolverTool', description='Use this tool to solve mathematical problems.', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'MathSolverTool_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x000002476C2D4720>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None), FunctionTool(name='HistoryExpertTool', description='Use this tool to provide detailed historical information and context.', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'HistoryExpertTool_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x000002476C2D4A40>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions=\"You are a triage agent. Determine whether a user's query is best handled by the MathSolverBot or the HistoryExpertBot, and route the query accordingly.\", prompt=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_0df535c959448d2600692fe7e30f40819a8247566adef5d846', content=[ResponseOutputText(annotations=[], text='The integral of \\\\( x^2 \\\\) is \\\\(\\\\frac{x^3}{3} + C\\\\), where \\\\(C\\\\) is the constant of integration.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message'), type='message_output_item')],\n",
       " 'raw_responses': [ModelResponse(output=[ResponseFunctionToolCall(arguments='{\"input\":\"integral of x^2\"}', call_id='call_WpGoEEMr9a6gEkl0TVoL4a66', name='MathSolverTool', type='function_call', id='fc_0df535c959448d2600692fe7dcf1d8819ab9f83b3ceeef8cf8', status='completed')], usage=Usage(requests=1, input_tokens=129, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=21, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=150), response_id='resp_0df535c959448d2600692fe7dc66f4819a80e1c9549f178541'),\n",
       "  ModelResponse(output=[ResponseOutputMessage(id='msg_0df535c959448d2600692fe7e30f40819a8247566adef5d846', content=[ResponseOutputText(annotations=[], text='The integral of \\\\( x^2 \\\\) is \\\\(\\\\frac{x^3}{3} + C\\\\), where \\\\(C\\\\) is the constant of integration.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=313, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=36, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=349), response_id='resp_0df535c959448d2600692fe7e29e1c819a9206b20c3e54821e')],\n",
       " 'final_output': 'The integral of \\\\( x^2 \\\\) is \\\\(\\\\frac{x^3}{3} + C\\\\), where \\\\(C\\\\) is the constant of integration.',\n",
       " 'input_guardrail_results': [],\n",
       " 'output_guardrail_results': [],\n",
       " 'tool_input_guardrail_results': [],\n",
       " 'tool_output_guardrail_results': [],\n",
       " 'context_wrapper': RunContextWrapper(context=None, usage=Usage(requests=2, input_tokens=442, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=57, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=499)),\n",
       " '_last_agent': Agent(name='TriageAgent', handoff_description=None, tools=[FunctionTool(name='MathSolverTool', description='Use this tool to solve mathematical problems.', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'MathSolverTool_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x000002476C2D4720>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None), FunctionTool(name='HistoryExpertTool', description='Use this tool to provide detailed historical information and context.', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'HistoryExpertTool_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x000002476C2D4A40>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions=\"You are a triage agent. Determine whether a user's query is best handled by the MathSolverBot or the HistoryExpertBot, and route the query accordingly.\", prompt=None, handoffs=[], model='gpt-4.1-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41903dd0",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:16px;background:#1e2a1e;margin:1em 0;padding:1em 1em 1em 3em;color:#eceff4;position:relative;box-shadow:0 6px 16px rgba(0,0,0,.4)\">\n",
    "  <b style=\"color:#a3be8c;font-size:1.25em\">Your Challenge:</b>\n",
    "  <ul style=\"margin:.6em 0 0;padding-left:1.2em;line-height:1.6\">\n",
    "    <li><b>Build a News Research Agent</b> that can research current events on any topic and provide a comprehensive summary of recent articles.</li>\n",
    "    <li>Choose your own approach: use <b>hosted tools</b> (like <code>WebSearchTool()</code>), <b>custom tools</b> (like Tavily API), or create an <b>agent routing system</b> with multiple specialist agents.</li>\n",
    "    <li>Test your agent with at least 2 different news topics and see how well it summarizes the information!</li>\n",
    "  </ul>\n",
    "  <div style=\"position:absolute;top:-.8em;left:-.8em;width:2.4em;height:2.4em;border-radius:50%;background:#a3be8c;color:#2e3440;display:flex;align-items:center;justify-content:center;font-weight:700;font-size:1.2em\">üí™</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1dc866",
   "metadata": {},
   "source": [
    "# Agent Handoffs\n",
    "\n",
    "This is a different concept to agents as tools. Think of agents as tools as a way to supplement your main agent. Your main agent is able to make use of other tools and use the output that it gets back but the conversation with the user remains with the main agent.\n",
    "\n",
    "In handoffs, you handoff the conversation to another agent (lets say a sales agent).\n",
    "\n",
    "**Why might we do this?**\n",
    "The use cases might be so niche that both these options will seem similar in terms of the actual output we get, the key difference is in the system instructions given to each agent. Each agent is going to have its own set of instructions and knowledge it has access to (as well as tone and style of writting for example) and this might be the deciding factor of wanting to use agents as tools or handoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31618d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "refund_agent = Agent(\n",
    "    name=\"RefundAgent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=\"You are a refund agent that processes refund requests based on company policy. For now say there are no refunds available\",\n",
    "    handoff_description=\"Handles refund requests from customers.\"\n",
    ")\n",
    "\n",
    "retention_agent = Agent(\n",
    "    name=\"RetentionAgent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=\"You are a retention agent that offers retention deals to customers considering cancellation. For now say that we are offering 20% off on everything\",\n",
    "    handoff_description=\"Handles customer retention and offers deals to prevent cancellations.\"\n",
    ")\n",
    "\n",
    "upsell_agent = Agent(\n",
    "    name=\"SalesAgent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=\"You are a sales agent that offers upsell options to customers based on their current subscriptions. For now say we have a premium plan available at 30% off.\",\n",
    "    handoff_description=\"Handles upselling and cross-selling to customers.\"\n",
    ")\n",
    "\n",
    "customer_service_agent = Agent(\n",
    "    name=\"CustomerServiceTriageAgent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=\"You are a customer service triage agent that chats with the user about their query then directs customer inquiries to the appropriate department based on the issue described. Do not ask for clarification.\",\n",
    "    handoffs=[refund_agent, retention_agent, upsell_agent]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "830495f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunResult:\n",
      "- Last agent: Agent(name=\"RefundAgent\", ...)\n",
      "- Final output (str):\n",
      "    Currently, there are no refunds available according to our company policy. However, I can assist you with canceling your subscription if you would like.\n",
      "- 5 new item(s)\n",
      "- 2 raw response(s)\n",
      "- 0 input guardrail result(s)\n",
      "- 0 output guardrail result(s)\n",
      "(See `RunResult` for more details)\n"
     ]
    }
   ],
   "source": [
    "results = await Runner.run(customer_service_agent, \"I want to cancel my subscription and get a refund.\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ee746",
   "metadata": {},
   "source": [
    "Here's how our customer service agent system works:\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    User([üë§ User Input]) --> TriageAgent([üéØ Customer Service Triage Agent])\n",
    "    \n",
    "    TriageAgent -->|Refund Request| RefundAgent([üí∞ Refund Agent])\n",
    "    TriageAgent -->|Cancellation/Retention| RetentionAgent([ü§ù Retention Agent])\n",
    "    TriageAgent -->|Upgrade/Upsell| UpsellAgent([üìà Sales Agent])\n",
    "    \n",
    "    RefundAgent --> Output1([üì§ User Output])\n",
    "    RetentionAgent --> Output2([üì§ User Output])\n",
    "    UpsellAgent --> Output3([üì§ User Output])\n",
    "    \n",
    "    style TriageAgent fill:#d08770,stroke:#2e3440,stroke-width:3px,color:#2e3440\n",
    "    style RefundAgent fill:#d08770,stroke:#2e3440,stroke-width:2px,color:#2e3440\n",
    "    style RetentionAgent fill:#d08770,stroke:#2e3440,stroke-width:2px,color:#2e3440\n",
    "    style UpsellAgent fill:#d08770,stroke:#2e3440,stroke-width:2px,color:#2e3440\n",
    "    style User fill:#5e81ac,stroke:#2e3440,stroke-width:2px,color:#eceff4\n",
    "    style Output1 fill:#5e81ac,stroke:#2e3440,stroke-width:2px,color:#eceff4\n",
    "    style Output2 fill:#5e81ac,stroke:#2e3440,stroke-width:2px,color:#eceff4\n",
    "    style Output3 fill:#5e81ac,stroke:#2e3440,stroke-width:2px,color:#eceff4\n",
    "```\n",
    "\n",
    "The **Customer Service Triage Agent** intelligently routes customer inquiries to the appropriate specialist agent based on the nature of the request. Each specialist agent then handles the query and provides a response back to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eecfc2",
   "metadata": {},
   "source": [
    "# Structured outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550bc3e6",
   "metadata": {},
   "source": [
    "Here's how our structured customer service workflow for the fictional company **Maven & Co.** operates:\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    Start([üë§ User Input]) --> Classify([üîç Classification Agent])\n",
    "    \n",
    "    Classify -->|books| BookAgent([üìö Book Agent])\n",
    "    Classify -->|clothing| ClothingAgent([üëó Clothing Agent])\n",
    "    Classify -->|retention| RetentionAgent([üéÅ Retention Agent])\n",
    "    Classify -->|order| OrderAgent([üì¶ Order Agent])\n",
    "    \n",
    "    BookAgent --> End1([üì§ User Response])\n",
    "    ClothingAgent --> End2([üì§ User Response])\n",
    "    RetentionAgent --> End3([üì§ User Response])\n",
    "    \n",
    "    OrderAgent --> CheckApproval{Human Approval\\nNeeded?}\n",
    "    \n",
    "    CheckApproval -->|No| End4([üì§ User Response])\n",
    "    CheckApproval -->|Yes| HumanReview([üë§ Human Reviews Order])\n",
    "    \n",
    "    HumanReview -->|Approved| OrderSuccess([‚úÖ Order Placed])\n",
    "    HumanReview -->|Rejected| OrderCancel([‚ùå Order Cancelled])\n",
    "    \n",
    "    style Classify fill:#88c0d0,stroke:#2e3440,stroke-width:3px,color:#2e3440\n",
    "    style BookAgent fill:#d08770,stroke:#2e3440,stroke-width:2px,color:#2e3440\n",
    "    style ClothingAgent fill:#d08770,stroke:#2e3440,stroke-width:2px,color:#2e3440\n",
    "    style RetentionAgent fill:#d08770,stroke:#2e3440,stroke-width:2px,color:#2e3440\n",
    "    style OrderAgent fill:#d08770,stroke:#2e3440,stroke-width:2px,color:#2e3440\n",
    "    style Start fill:#5e81ac,stroke:#2e3440,stroke-width:2px,color:#eceff4\n",
    "    style End1 fill:#5e81ac,stroke:#2e3440,stroke-width:2px,color:#eceff4\n",
    "    style End2 fill:#5e81ac,stroke:#2e3440,stroke-width:2px,color:#eceff4\n",
    "    style End3 fill:#5e81ac,stroke:#2e3440,stroke-width:2px,color:#eceff4\n",
    "    style End4 fill:#5e81ac,stroke:#2e3440,stroke-width:2px,color:#eceff4\n",
    "    style CheckApproval fill:#ebcb8b,stroke:#2e3440,stroke-width:2px,color:#2e3440\n",
    "    style HumanReview fill:#b48ead,stroke:#2e3440,stroke-width:2px,color:#eceff4\n",
    "    style OrderSuccess fill:#a3be8c,stroke:#2e3440,stroke-width:2px,color:#2e3440\n",
    "    style OrderCancel fill:#bf616a,stroke:#2e3440,stroke-width:2px,color:#eceff4\n",
    "```\n",
    "\n",
    "This workflow demonstrates a **deterministic, structured output system** where:\n",
    "- The **Classification Agent** routes requests to specialized agents\n",
    "- Each specialist agent returns structured data (Pydantic models)\n",
    "- The **Order Agent** includes human-in-the-loop approval for critical actions\n",
    "- All interactions end with a user response or final state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e7b73d",
   "metadata": {},
   "source": [
    "### Maven & Co. Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2936b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ClassificationResponse(BaseModel):\n",
    "    category: str\n",
    "    reasoning: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b631076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    'category': [],\n",
    "    'reasoning': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c16ae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_agent = Agent(\n",
    "    name=\"ClassificationAgent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=\"You are a classification agent that categorizes customer inquiries into one of four categories: books, clothing, retention, or order. Analyze the user's query and determine which category best fits their request.\",\n",
    "    output_type=ClassificationResponse\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76674471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunResult:\n",
      "- Last agent: Agent(name=\"ClassificationAgent\", ...)\n",
      "- Final output (ClassificationResponse):\n",
      "    {\n",
      "      \"category\": \"order\",\n",
      "      \"reasoning\": \"The user's request involves returning a book they ordered, which pertains to the order process rather than the book's content or category itself. Therefore, the best fit is 'order' as it deals with transaction issues like returns.\"\n",
      "    }\n",
      "- 1 new item(s)\n",
      "- 1 raw response(s)\n",
      "- 0 input guardrail result(s)\n",
      "- 0 output guardrail result(s)\n",
      "(See `RunResult` for more details)\n"
     ]
    }
   ],
   "source": [
    "results = await Runner.run(classification_agent, \"I want to return a book I ordered last week.\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e05c20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'order'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.final_output.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4fe59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae3d18a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ClassificationResponse(BaseModel):\n",
    "    reason: str = Field(..., description=\"The reasoning behind the classification\")\n",
    "    category: str = Field(..., description=\"The category of the customer inquiry\")\n",
    "    confidence: float = Field(..., description=\"The confidence level of the classification from 0 to 1\")\n",
    "    \n",
    "\n",
    "class BookResponse(BaseModel):\n",
    "    reason: str = Field(..., description=\"The reason for the book recommendation\")\n",
    "    response: str = Field(..., description=\"Personalized book recommendation message\")\n",
    "\n",
    "\n",
    "class ClothingResponse(BaseModel):\n",
    "    reason: str = Field(..., description=\"The reason for the clothing recommendation\")\n",
    "    response: str = Field(..., description=\"Personalized clothing recommendation message\")\n",
    "\n",
    "\n",
    "class RetentionResponse(BaseModel):\n",
    "    offer: str = Field(..., description=\"The retention offer being provided\")\n",
    "    discount_percentage: float = Field(..., description=\"Discount percentage offered\")\n",
    "    response: str = Field(..., description=\"Personalized retention message to the customer\")\n",
    "\n",
    "\n",
    "class OrderResponse(BaseModel):\n",
    "    human_approval: bool = Field(..., description=\"Indicates if human approval is required for the order. Only to be used right before the order is about to be executed.\")\n",
    "    order_item_name: str = Field(..., description=\"Name of the item to be ordered\")\n",
    "    item_id: int = Field(..., description=\"Unique identifier of the item to be ordered\")\n",
    "    order_id: int = Field(..., description=\"Unique identifier for the order\")\n",
    "    order_amount: float = Field(..., description=\"Total amount for the order in USD\")\n",
    "    response: str = Field(..., description=\"Next steps for completing the order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38169ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Agent\n",
    "classification_agent = Agent(\n",
    "    name=\"ClassificationAgent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=\"You are a classification agent that categorizes customer inquiries into one of four categories: books, clothing, retention, or order. Analyze the user's query and determine which category best fits their request.\",\n",
    "    output_type=ClassificationResponse\n",
    ")\n",
    "\n",
    "# Book Agent with fictional inventory\n",
    "book_inventory = \"\"\"\n",
    "Available Books:\n",
    "1. \"The Midnight Library\" by Matt Haig - $16.99 (12 in stock)\n",
    "2. \"Atomic Habits\" by James Clear - $19.99 (25 in stock)\n",
    "3. \"The Psychology of Money\" by Morgan Housel - $18.50 (8 in stock)\n",
    "4. \"Project Hail Mary\" by Andy Weir - $21.99 (15 in stock)\n",
    "5. \"The Thursday Murder Club\" by Richard Osman - $17.99 (20 in stock)\n",
    "\"\"\"\n",
    "\n",
    "book_agent = Agent(\n",
    "    name=\"BookAgent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=f\"You are a book specialist agent. Help customers find books from our inventory. {book_inventory}\",\n",
    "    output_type=BookResponse\n",
    ")\n",
    "\n",
    "# Clothing Agent with fictional inventory\n",
    "clothing_inventory = \"\"\"\n",
    "Available Women's Clothing:\n",
    "1. \"Elegant Silk Blouse\" - Size M - $89.99 (10 in stock)\n",
    "2. \"Classic Denim Jacket\" - Size L - $124.99 (5 in stock)\n",
    "3. \"Floral Summer Dress\" - Size S - $79.99 (18 in stock)\n",
    "4. \"Cashmere Cardigan\" - Size M - $149.99 (7 in stock)\n",
    "5. \"High-Waist Trousers\" - Size L - $94.99 (12 in stock)\n",
    "\"\"\"\n",
    "\n",
    "clothing_agent = Agent(\n",
    "    name=\"ClothingAgent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=f\"You are a women's clothing specialist agent. Help customers find clothing items from our inventory. {clothing_inventory}\",\n",
    "    output_type=ClothingResponse\n",
    ")\n",
    "\n",
    "# Retention Agent\n",
    "retention_agent_structured = Agent(\n",
    "    name=\"RetentionAgent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=\"You are a customer retention specialist. Your goal is to retain customers by offering them attractive promotional deals. Offer a 25% discount valid for 30 days on their next purchase. Be persuasive but respectful.\",\n",
    "    output_type=RetentionResponse\n",
    ")\n",
    "\n",
    "# Order Agent\n",
    "order_agent = Agent(\n",
    "    name=\"OrderAgent\",\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    instructions=\"You are an order processing agent. Guide customers through placing their orders.\" \\\n",
    "    \" Discuss items they want to purchase, quantities, shipping preferences, and payment options. Be helpful and thorough.\" \\\n",
    "    \" Always ask for human approval before finalizing any order.\",\n",
    "    output_type=OrderResponse\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e813cc",
   "metadata": {},
   "source": [
    "### Workflow Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bc5344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0dd67b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Input: I want a book similar to mockingjay\n",
      "\n",
      "Classifying the query...\n",
      "Classification: books\n",
      " (Confidence: 0.95)\n",
      "Reasoning: The user is asking for a book similar to 'Mockingjay', which clearly relates to books rather than clothing, retention, or order issues.\n",
      "\n",
      "Routing to Book Agent...\n",
      "Book Response:  Based on your interest in 'Mockingjay', I recommend 'The Midnight Library' by Matt Haig. It offers a captivating exploration of choices and parallel lives with a thrilling and emotional story that fans of dystopian and speculative fiction often enjoy.\n",
      "Reason:  Since you enjoyed 'Mockingjay', which is a thrilling dystopian novel with strong characters and suspense, I recommend 'The Midnight Library' by Matt Haig. It explores life choices and alternate realities with an engaging and thought-provoking narrative, appealing to readers who appreciate deep, compelling stories.\n",
      "User Input: What clothing articles are similar to this theme of the mockingjay?\n",
      "\n",
      "Classifying the query...\n",
      "Classification: clothing\n",
      " (Confidence: 0.90)\n",
      "Reasoning: The user is asking for clothing articles that are similar to the theme of 'Mockingjay', which pertains to clothing and thematic fashion items inspired by the book or its motifs.\n",
      "\n",
      "Routing to Clothing Agent...\n",
      "Clothing Response:  For a clothing style inspired by the 'Mockingjay' theme, I suggest the 'Classic Denim Jacket' (Size L) because it conveys strength and rebellion, key themes of the story. Additionally, the 'Elegant Silk Blouse' (Size M) adds a touch of grace and resilience, reflecting the character's complexity.\n",
      "Reason:  Considering the theme of 'Mockingjay', which embodies rebellion, strength, and fiery determination, I recommend the 'Classic Denim Jacket' in Size L for its rugged, resilient style symbolizing a rebellious spirit, and the 'Elegant Silk Blouse' in Size M for a touch of sophistication and inner strength.\n",
      "User Input: I want to order that jacket\n",
      "\n",
      "Classifying the query...\n",
      "Classification: order\n",
      " (Confidence: 0.95)\n",
      "Reasoning: The user expresses a desire to order the jacket, which is related to placing an order for a clothing item, fitting both the order and clothing categories. However, since the primary intent is to make an order, the appropriate category is 'order'.\n",
      "\n",
      "Routing to Order Agent...\n",
      "Order requires human approval. Escalating to a human agent.\n",
      "  Item: Classic Denim Jacket\n",
      " Order ID: 1001\n",
      " Amount: $79.99\n",
      "Order approved and processed.\n",
      "User Input: exit\n",
      "\n",
      "Exiting the system. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while True:\n",
    "    # Step 1: Get a user response\n",
    "    user_input = input(\"You: \")\n",
    "    print(f\"User Input: {user_input}\\n\")\n",
    "    input_list.append({'role': 'user', 'content': user_input})\n",
    "\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Exiting the system. Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Step 2: Classify the user query\n",
    "    print(\"Classifying the query...\")\n",
    "    classification_results = await Runner.run(classification_agent, input_list)\n",
    "    classification_output = classification_results.final_output\n",
    "    input_list = classification_results.to_input_list()\n",
    "    print(f\"Classification: {classification_output.category}\\n (Confidence: {classification_output.confidence:.2f})\")\n",
    "    print(f\"Reasoning: {classification_output.reason}\\n\")\n",
    "\n",
    "    # Step 3: Route to appropriate agent based on classification\n",
    "    if classification_output.category == \"books\":\n",
    "        print(\"Routing to Book Agent...\")\n",
    "        book_results = await Runner.run(book_agent, input_list)\n",
    "        book_output = book_results.final_output\n",
    "        input_list = book_results.to_input_list()\n",
    "        print(\"Book Response: \", book_results.final_output.response)\n",
    "        print(\"Reason: \", book_results.final_output.reason)\n",
    "\n",
    "    elif classification_output.category == \"clothing\":\n",
    "        print(\"Routing to Clothing Agent...\")\n",
    "        clothing_results = await Runner.run(clothing_agent, input_list)\n",
    "        clothing_output = clothing_results.final_output\n",
    "        input_list = clothing_results.to_input_list()\n",
    "        print(\"Clothing Response: \", clothing_results.final_output.response)\n",
    "        print(\"Reason: \", clothing_results.final_output.reason)\n",
    "\n",
    "    elif classification_output.category == \"retention\":\n",
    "        print(\"Routing to Retention Agent...\")\n",
    "        retention_results = await Runner.run(retention_agent_structured, input_list)\n",
    "        retention_output = retention_results.final_output\n",
    "        input_list = retention_results.to_input_list()\n",
    "        print(\"Retention Response: \", retention_results.final_output.response)\n",
    "        print(\"Reason: \", retention_results.final_output.reason)\n",
    "\n",
    "    elif classification_output.category == \"order\":\n",
    "        print(\"Routing to Order Agent...\")\n",
    "        agent_results = await Runner.run(order_agent, input_list)\n",
    "        order_output = agent_results.final_output\n",
    "        input_list = agent_results.to_input_list()\n",
    "\n",
    "        if order_output.human_approval:\n",
    "            print(\"Order requires human approval. Escalating to a human agent.\")\n",
    "            print(f\"  Item: {order_output.order_item_name}\")\n",
    "            print(f\" Order ID: {order_output.order_id}\")\n",
    "            print(f\" Amount: ${order_output.order_amount:.2f}\")\n",
    "\n",
    "            approval = input(\"Approve order? (yes/no): \")\n",
    "\n",
    "            if approval.lower() == \"yes\":\n",
    "                print(\"Order approved and processed.\")\n",
    "            else:\n",
    "                print(\"Order denied.\")\n",
    "        else:\n",
    "            print(\"Order processed automatically.\")\n",
    "            print(order_output.response)\n",
    "\n",
    "    else:\n",
    "        print(\"Unable to classify the inquiry. Please contact customer support for further assistance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad603ef",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:16px;background:#1e2a1e;margin:1em 0;padding:1em 1em 1em 3em;color:#eceff4;position:relative;box-shadow:0 6px 16px rgba(0,0,0,.4)\">\n",
    "  <b style=\"color:#a3be8c;font-size:1.25em\">Your Challenge:</b>\n",
    "  <ul style=\"margin:.6em 0 0;padding-left:1.2em;line-height:1.6\">\n",
    "    <li><b>Deploy Maven & Co. as a Web App!</b> Take the customer service workflow you just learned and turn it into an interactive application using either <b>Gradio</b> or <b>Streamlit</b>.</li>\n",
    "    <li>Your app should:\n",
    "      <ul style=\"margin-top:0.3em\">\n",
    "        <li>Accept user input through a chat interface</li>\n",
    "        <li>Display the classification results (category and confidence)</li>\n",
    "        <li>Show agent responses in a user-friendly format</li>\n",
    "        <li>Handle the human approval step for orders interactively</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "  </ul>\n",
    "  <div style=\"position:absolute;top:-.8em;left:-.8em;width:2.4em;height:2.4em;border-radius:50%;background:#a3be8c;color:#2e3440;display:flex;align-items:center;justify-content:center;font-weight:700;font-size:1.2em\">üí™</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01a4d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
