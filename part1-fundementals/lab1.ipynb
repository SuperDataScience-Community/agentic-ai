{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96520fca",
   "metadata": {},
   "source": [
    "# Basic Agentic Workflow\n",
    "\n",
    "Helloooo everyone and welcome to an exciting lesson on Agentic AI! ðŸŽ‰\n",
    "\n",
    "Today, we're diving into **prompt chaining** agentic workflow pattern. What's that? It's just passing the output from one LLM to the next, step by step. Think of it like a relay race, but with prompts instead of batons.\n",
    "\n",
    "We'll keep things super simple: manually run each cell, watch the magic happen, and see how chaining LLM calls lets us build more complex workflows.\n",
    "\n",
    "Ready to see how agents can work together? Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655eac71",
   "metadata": {},
   "source": [
    "## As always, libraries first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f696afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# check if API keys are set\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Missing OpenAI API key\")\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"Missing Gemini API key\")\n",
    "if not ANTHROPIC_API_KEY:\n",
    "    raise ValueError(\"Missing Anthropic API key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bab264f",
   "metadata": {},
   "source": [
    "You can set your API Keys for each of the LLM providers using the following links:\n",
    "\n",
    "- [OpenAI](https://platform.openai.com/api-keys)\n",
    "- [Anthropic](https://console.anthropic.com/settings/keys)\n",
    "- [Gemini](https://aistudio.google.com/app/apikey)\n",
    "\n",
    "Once you have created the API Keys, you can store them on your `.env` file at the root of this repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91357479",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:16px;background:#2e3440;margin:1em 0;padding:1em 1em 1em 3em;color:#eceff4;position:relative;box-shadow:0 6px 16px rgba(0,0,0,.4)\">\n",
    "    <b style=\"color:#88c0d0;font-size:1.25em\">Info:</b>\n",
    "    <ul style=\"margin:.6em 0 0;padding-left:1.2em;line-height:1.6\">\n",
    "        <li>You can complete this entire notebook using just OpenAI models if you prefer!</li>\n",
    "        <li>It's absolutely fine to skip Anthropic and Gemini for now â€” the workflow works perfectly with only OpenAI.</li>\n",
    "        <li>Feel free to experiment with other providers later, but don't let missing API keys slow you down.</li>\n",
    "    </ul>\n",
    "    <div style=\"position:absolute;top:-.8em;left:-.8em;width:2.4em;height:2.4em;border-radius:50%;background:#88c0d0;color:#2e3440;display:flex;align-items:center;justify-content:center;font-weight:700;font-size:1.2em\">ðŸ’¡</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6ed0b8",
   "metadata": {},
   "source": [
    "## The Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01562382",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph LR\n",
    "    A[Generate Tickets] --> B[Classify Priority] --> C[Respond to Tickets]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8641ab",
   "metadata": {},
   "source": [
    "## Lets start with using OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24530e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab44e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages list\n",
    "message = \"I want you to generate a customer support ticket for a 3rd party re-seller. \"\n",
    "message += \"The ticket should be a single sentence describing a common issue a customer might face with their product or service. \"\n",
    "message += \"Please ensure the ticket is varied and covers different types of problems. \"\n",
    "message += \"Do not give any subjects, only the body of the ticket.\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": message}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa74d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response\n",
    "\n",
    "openai_response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "ticket = openai_response.choices[0].message.content\n",
    "# print(f\"### Generated Ticket:\\n{ticket}\")\n",
    "display(Markdown(f\"### Generated Ticket:\\n{ticket}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ec94e3",
   "metadata": {},
   "source": [
    "I love markdown. It is a lightweight method of rendering and formatting text that is super versatile without having to use heavy softwares like MS Word or Google Docs.\n",
    "\n",
    "You can learn more about markdown sytanx [here](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "A really informative YouTube video talking about the [Unreasonable Effectiveness of Plain Text](https://www.youtube.com/watch?v=WgV6M1LyfNY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38015b29",
   "metadata": {},
   "source": [
    "## Lets pass these on to an Anthropic model and ask it to classify the priority level of each ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d3443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anthropic client\n",
    "anthropic_client = OpenAI(api_key=ANTHROPIC_API_KEY, base_url=\"https://api.anthropic.com/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4affb2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages list\n",
    "message = \"I want you to classify the priority of the following customer support ticket. \"\n",
    "message += \"The ticket is as follows: \"+ ticket + \" \"\n",
    "message += \"Please classify the priority as either 'Low', 'Medium', or 'High'. \"\n",
    "message += \"Respond with only the priority level.\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": message}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c7c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response\n",
    "\n",
    "anthropic_response = anthropic_client.chat.completions.create(\n",
    "    model=\"claude-3-5-haiku-latest\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "priority = anthropic_response.choices[0].message.content\n",
    "display(Markdown(f\"### Classified Priority:\\n{priority}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed235e15",
   "metadata": {},
   "source": [
    "## Now Gemini should determine the appropriate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2304b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gemini client\n",
    "gemini_client = OpenAI(api_key=GEMINI_API_KEY, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b123501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages list\n",
    "\n",
    "message = \"You are to determine an appropriate response to the following customer support ticket. \"\n",
    "message += \"The ticket is as follows: \"+ ticket + \" \"\n",
    "message += \"The priority level of this ticket is: \" + priority + \" \"\n",
    "message += \"Please provide a response that addresses the customer's issue in a short and concise manner. \"\n",
    "    \n",
    "messages = [{\"role\": \"user\", \"content\": message}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3addbecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response\n",
    "\n",
    "gemini_response = gemini_client.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "response = gemini_response.choices[0].message.content\n",
    "display(Markdown(f\"### Generated Response:\\n{response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be180d46",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:16px;background:#1e2a1e;margin:1em 0;padding:1em 1em 1em 3em;color:#eceff4;position:relative;box-shadow:0 6px 16px rgba(0,0,0,.4)\">\n",
    "    <b style=\"color:#a3be8c;font-size:1.25em\">Your Challenge:</b>\n",
    "    <ul style=\"margin:.6em 0 0;padding-left:1.2em;line-height:1.6\"></ul>\n",
    "        <li>Recreate the customer support ticket workflow using an <b>evaluator-optimizer agentic workflow pattern</b> instead of prompt chaining.</li>\n",
    "        <li>Your evaluator agent should assess the quality and completeness of each ticket and suggest improvements.</li>\n",
    "        <li>Your optimizer agent should revise the tickets based on evaluator feedback, aiming for clarity and actionable details.</li>\n",
    "        <li>Try to implement this using at least two LLM calls (one for evaluation, one for optimization) and display the before/after results.</li>\n",
    "        <li>Share your work in the community-contributions folder by creating a folder with your name. Eg. shaheer-airaj.</li>\n",
    "    </ul>\n",
    "    <div style=\"position:absolute;top:-.8em;left:-.8em;width:2.4em;height:2.4em;border-radius:50%;background:#a3be8c;color:#2e3440;display:flex;align-items:center;justify-content:center;font-weight:700;font-size:1.2em\">ðŸ’ª</div>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
