{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76aa0469",
   "metadata": {},
   "source": [
    "# Structured Outputs\n",
    "\n",
    "LLMs regurgitate out text and that is great for so many applications. But in order to build strong, robust systems and applications, we need to make sense of the chaos sometimes by receiving a pre-determined structured output everytime an LLM is called."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54393e",
   "metadata": {},
   "source": [
    "## As always, libraries first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07683da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# check if API keys are set\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Missing OpenAI API key\")\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"Missing Gemini API key\")\n",
    "if not ANTHROPIC_API_KEY:\n",
    "    raise ValueError(\"Missing Anthropic API key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e567598a",
   "metadata": {},
   "source": [
    "## The Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043a7425",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph LR\n",
    "    A[Generate Ticket] --> B[Respond to Ticket]\n",
    "    B --> C[Evaluate Response]\n",
    "    C --> B\n",
    "    C --> D[Final Output]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b1446b",
   "metadata": {},
   "source": [
    "## Introducing the Pydantic library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a7c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class CustomerTicket(BaseModel):\n",
    "    ticket: str\n",
    "    priority: str\n",
    "    assigned_to: str\n",
    "\n",
    "class TicketResponse(BaseModel):\n",
    "    response: str\n",
    "    resolution_time: str\n",
    "\n",
    "class TicketEvaluation(BaseModel):\n",
    "    passed: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec10603",
   "metadata": {},
   "source": [
    "## Calling OpenAI to generate support tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages list\n",
    "user_message = \"I want you to generate a customer support ticket for a 3rd party tech re-seller. \"\n",
    "user_message += \"The ticket should be a single sentence describing a common issue a customer might face with their product or service. \"\n",
    "user_message += \"Please ensure the ticket is varied and covers different types of problems.\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": user_message}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccede81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "normal_response = response.choices[0].message.content\n",
    "display(Markdown(f\"### Normal Response:\\n{normal_response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3334742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structured response\n",
    "structured_response = client.chat.completions.parse(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages,\n",
    "    response_format=CustomerTicket\n",
    ")\n",
    "\n",
    "structured_response = structured_response.choices[0].message.parsed\n",
    "display(Markdown(f\"### Structured Response:\\n{structured_response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea053ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_response.ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9537b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_response.priority"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e222b10",
   "metadata": {},
   "source": [
    "## Responding to the ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d734a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages list\n",
    "message = \"You are to propose a resolution for the following customer support ticket. \\n\\n\"\n",
    "message += f\"Ticket: {structured_response.ticket}\\n\"\n",
    "message += f\"Priority: {structured_response.priority}\\n\\n\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": message}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc87ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structured response\n",
    "ticket_response = client.chat.completions.parse(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages,\n",
    "    response_format=TicketResponse\n",
    ")\n",
    "\n",
    "ticket_response = ticket_response.choices[0].message.parsed\n",
    "display(Markdown(f\"### Response:\\n{ticket_response.response}\"))\n",
    "display(Markdown(f\"### Resolution Time:\\n{ticket_response.resolution_time}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c5907b",
   "metadata": {},
   "source": [
    "## Lets evaluate our response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db24768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages list\n",
    "message = \"You are to evaluate the proposed resolution for the following customer support ticket. \"\n",
    "message += \"You will determine if the proposed resolution is appropriate for the ticket and priority level. \"\n",
    "message += \"tickets\\n\\n\"\n",
    "message += f\"Ticket: {structured_response.ticket}\\n\"\n",
    "message += f\"Priority: {structured_response.priority}\\n\\n\"\n",
    "message += f\"Proposed Resolution: {ticket_response.response}\\n\"\n",
    "message += f\"Proposed Resolution Time: 24 days\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": message}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ddbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b53969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate response\n",
    "evaluator_response = client.chat.completions.parse(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages,\n",
    "    response_format=TicketEvaluation\n",
    ")\n",
    "\n",
    "evaluator_response = evaluator_response.choices[0].message.parsed\n",
    "display(Markdown(f\"### Passed:\\n{evaluator_response.passed}\"))\n",
    "display(Markdown(f\"### Feedback:\\n{evaluator_response.feedback}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b589c6",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:16px;background:#1e2a1e;margin:1em 0;padding:1em 1em 1em 3em;color:#eceff4;position:relative;box-shadow:0 6px 16px rgba(0,0,0,.4)\">\n",
    "  <b style=\"color:#a3be8c;font-size:1.25em\">Your Challenge:</b>\n",
    "  <ul style=\"margin:.6em 0 0;padding-left:1.2em;line-height:1.6\">\n",
    "    <li>Hey everyone! Ready to flex those agentic muscles? ðŸŽ‰ Build a workflow just like the ticket system above, but for <b>product reviews</b>!</li>\n",
    "    <li>Your workflow should:\n",
    "      <ul>\n",
    "        <li>Generate a product review (think: electronics, books, or your favorite kitchen gadget)</li>\n",
    "        <li>Respond to the review (company reply, moderation, or a witty bot response)</li>\n",
    "        <li>Evaluate the response (is it helpful, polite, and on point?)</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "    <li>Use structured outputs and Pydantic models for each step, just like we did above.</li>\n",
    "    <li>Include an evaluator step to assess the quality of the response.</li>\n",
    "    <li>Hereâ€™s a suggested workflow to get your creative gears turning:</li>\n",
    "  </ul>\n",
    "  <div style=\"position:absolute;top:-.8em;left:-.8em;width:2.4em;height:2.4em;border-radius:50%;background:#a3be8c;color:#2e3440;display:flex;align-items:center;justify-content:center;font-weight:700;font-size:1.2em\">ðŸ’ª</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b609d884",
   "metadata": {},
   "source": [
    "### Suggested Workflow\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[Generate Review] --> B[Respond to Review]\n",
    "    B --> C[Evaluate Response]\n",
    "    C --> B\n",
    "    C --> D[Final Output]\n",
    "```\n",
    "\n",
    "Try to use structured outputs and Pydantic models for each step, just like in the notebook above. Include an evaluator step to assess the quality of the response."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
