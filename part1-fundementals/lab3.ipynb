{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a650a62",
   "metadata": {},
   "source": [
    "# Function Calling/Tool Use\n",
    "\n",
    "\n",
    "## Just a quick definition\n",
    "\n",
    "Function calling in the context of Large Language Models (LLMs) refers to the ability of the model to invoke external functions or tools during its response generation. Instead of only generating text, the LLM can recognize when a task requires external data or computation, call a predefined function with the appropriate arguments, and then use the function's output to continue its response.\n",
    "\n",
    "Think of having a super smart robot that you can only speak with. Pretty useless at doing anything aside from talking. Now imagine you have given that robot a hammer and some nails. It can now put up that wall painting that's been waiting forever to be hung :D\n",
    "\n",
    "Except, the way we as AI Engineers give AI tools is by defining python functions and describing that function in detail to the LLM so it knows what tools it has access to, what each tool can do, what are its inputs and expected outputs.\n",
    "\n",
    "Just remember, a *tool* in its simplest form is just a *python function* that you have defined. It can be as simple as a calculator function or something like being able to call external APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057f0cfa",
   "metadata": {},
   "source": [
    "![tool-use](../images/tool-use.png)\n",
    "\n",
    "*Image courtesy of [API Deck](https://www.apideck.com/blog/llm-tool-use-and-function-calling)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa669de",
   "metadata": {},
   "source": [
    "## Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bffb0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if OPENAI_API_KEY is None:\n",
    "    raise Exception(\"API key is missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3d86cc",
   "metadata": {},
   "source": [
    "## Step 2: Define a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3997d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_weather(latitude, longitude):\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfddda44",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_weather(24.343627, 54.497922)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4b3e24",
   "metadata": {},
   "source": [
    "## Step 3: Call a chat model normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc1597",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    input=[\n",
    "        {\"role\": \"user\", \"content\": \"What is the weather like in Abu Dhabi now?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d64a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c75fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.output[0].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45ab349",
   "metadata": {},
   "source": [
    "## Step 4: Define the input schema for our tool\n",
    "\n",
    "Lets try giving our `get_weather` function as a tool to our AI.\n",
    "\n",
    "We will first need to define the tool in a format OpenAI can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ead465",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    'type': 'function',\n",
    "    'name': 'get_weather',\n",
    "    'description': 'Fetch the current weather for a specific location',\n",
    "    'parameters': {\n",
    "        'type': 'object',\n",
    "        'properties': {\n",
    "            'latitude': {'type': 'number'},\n",
    "            'longitude': {'type': 'number'}\n",
    "        },\n",
    "        'required': ['latitude', 'longitude'],\n",
    "        'additionalProperties': False\n",
    "    },\n",
    "    'strict': True\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a9f2e8",
   "metadata": {},
   "source": [
    "## Step 5: Pass the tool schema over to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e10f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_messages = [{\"role\": \"user\", \"content\": \"What is the weather like in Abu Dhabi now?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecd57bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    input=input_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe27b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ba891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.output[0].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fea85f",
   "metadata": {},
   "source": [
    "## Step 6: Format the tool call response from the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4619e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tool_call = response.output[0]\n",
    "args = json.loads(tool_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeef1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f003b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9ff324",
   "metadata": {},
   "source": [
    "## Step 7: Pass on the tool call arguments to our tool/python function\n",
    "\n",
    "We now need to pass on the arguments received by the model to our python function or tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec267d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_weather(args['latitude'], args['longitude'])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1829435",
   "metadata": {},
   "source": [
    "## Step 8: Append the response of the tool into the message list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffcaa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_messages.append(tool_call)\n",
    "\n",
    "input_messages.append({\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": tool_call.call_id,\n",
    "    \"output\": str(result)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(input_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a76b0c",
   "metadata": {},
   "source": [
    "## Step 9: Pass the message list into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2444c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = client.responses.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    input=input_messages,\n",
    "    tools=tools\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcba22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_2.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30de53b",
   "metadata": {},
   "source": [
    "# Resources:\n",
    "\n",
    "- [OpenAIs Function Calling Guide](https://platform.openai.com/docs/guides/function-calling?api-mode=responses)\n",
    "- [Anthropics Tool Use Guide with Claude](https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/overview)\n",
    "- [Function Calling with Gemini API](https://ai.google.dev/gemini-api/docs/function-calling?example=meeting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bc4aab",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:16px;background:#1e2a1e;margin:1em 0;padding:1em 1em 1em 3em;color:#eceff4;position:relative;box-shadow:0 6px 16px rgba(0,0,0,.4)\">\n",
    "  <b style=\"color:#a3be8c;font-size:1.25em\">Your Challenge:</b>\n",
    "  <div style=\"position:absolute;top:-.8em;left:-.8em;width:2.4em;height:2.4em;border-radius:50%;background:#a3be8c;color:#2e3440;display:flex;align-items:center;justify-content:center;font-weight:700;font-size:1.2em\">ðŸ’ª</div>\n",
    "\n",
    "  <br>\n",
    "  Now that you've seen how to define a Python function as a tool and connect it to an LLM, it's time to get creative!\n",
    "\n",
    "  <b>Pick your challenge</b><br>\n",
    "  <b>1. Wikipedia Article Summarizer</b><br>\n",
    "  - Fetch a wikipedia article you are interested in learning about and have an LLM summarize it<br>\n",
    "  - <a href=\"https://pypi.org/project/Wikipedia-API/\">Wikipedia API</a><br>\n",
    "\n",
    "  <b>2. News Summarizer</b><br>\n",
    "  - Fetch latest headlines or news by topic.<br>\n",
    "  - <a href=\"https://newsapi.org\">NewsAPI</a><br>\n",
    "  - <a href=\"https://currentsapi.services/en/docs/\">CurrentsAPI</a><br>\n",
    "\n",
    "  <b>3. Stock Market Data</b><br>\n",
    "  - Get real-time stock prices or company info<br>\n",
    "  - <a href=\"https://www.alphavantage.co/\">Alpha Vantage</a><br>\n",
    "  - <a href=\"https://pypi.org/project/yfinance/\">yfinance</a><br>\n",
    "\n",
    "  <b>4. Movie Info</b><br>\n",
    "  - Get movie ratings, cast, plot summaries.<br>\n",
    "  - <a href=\"https://imdbapi.dev/\">IMDb</a><br>\n",
    "  - <a href=\"https://www.omdbapi.com/\">OMDb API</a><br>\n",
    "\n",
    "  <b>5. NASA API</b><br>\n",
    "  - Astronomy facts, country data, etc.<br>\n",
    "  - <a href=\"https://api.nasa.gov/\">NASA APIs</a><br>\n",
    "\n",
    "  <b>6. Your own custom tool</b><br>\n",
    "  - Think of a real-world use case where an LLM could benefit from calling a custom function.<br>\n",
    "\n",
    "  <hr>\n",
    "\n",
    "  <b>Tips</b>:<br>\n",
    "  - Use clear function names and docstrings.<br>\n",
    "  - Handle input arguments and outputs carefully.<br>\n",
    "  - Print the LLM's tool call and your function's output in a readable way.<br>\n",
    "\n",
    "  Be sure to place your submissions in <code>part1-fundamentals/community-contributions/&lt;your-name&gt;</code><br>\n",
    "\n",
    "  I'm super excited to see what you come up with :D\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
